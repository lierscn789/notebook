{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 点估计的常用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念回顾\n",
    "\n",
    "**点估计**\n",
    "\n",
    "样本的任何一个函数$W\\left(X_{1}, \\cdots, X_{n}\\right)$称为一个点估计量（Point Estimator），即任何一个统计量就是一个点估计量。\n",
    "\n",
    "注意\n",
    "\n",
    "- 上述定义没有提及这个点估计量与待估计参数之间的任何对应。\n",
    "\n",
    "- 估计量和估计值的区别。估计量是样本的一个函数，而估计值是一个估计量的实现值，它是从样本抽取之后的实际观测值得到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩法\n",
    "\n",
    "矩法也许是最早的求点估计量的方法，至少可以追随到十九世纪末的Karl Pearon。它的优点是使用简单，从而几乎总是可以求出估计值。尽管在很多情况下，矩法导出的估计量还需要改进，但是在其他方法难以实施的时候，它仍然不失为一个很好的工作起点。\n",
    "\n",
    "**矩**\n",
    "\n",
    "对任意整数$n$，$X$的$n$阶矩（nth moment），记为$\\mu_{n}^{\\prime}$，定义为\n",
    "\n",
    "$$\\mu_{n}^{\\prime}=\\mathrm{E} X^{n}$$\n",
    "\n",
    "$X$的$n$阶中心距（nth central moment）,记做$\\mu_{n}$，定义为\n",
    "\n",
    "$$\\mu_{n}=\\mathrm{E}(X-\\mu)^{n}$$\n",
    "\n",
    "其中$\\mu=\\mu_{1}^{\\prime}=\\mathrm{E} X$。\n",
    "\n",
    "<br>\n",
    "\n",
    "设$X_{1}, \\cdots, X_{n}$来自以$f\\left(x | \\theta_{1}, \\cdots, \\theta_{k}\\right)$为其概率密度函数的总体的样本。令前$k$阶的样本矩与相应的前$k$阶总体矩相等，这样就得到一个联立方程组，求解即可得到矩估计量。\n",
    "\n",
    "即定义\n",
    "\n",
    "$$\\begin{aligned} m_{1} &=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}^{1}, \\quad \\mu_{1}^{\\prime}=\\mathrm{E} X^{1} \\\\ m_{2} &=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}^{2}, \\quad \\mu_{2}^{\\prime}=\\mathrm{E} X^{2} \\end{aligned}$$\n",
    "$$\\vdots$$\n",
    "$$m_{k}=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}^{k}, \\quad \\mu_{k}^{\\prime}=\\mathrm{E} X^{k}$$\n",
    "\n",
    "则可通过求解下述方程组得到矩估计量\n",
    "\n",
    "$$m_{1}=\\mu_{1}^{\\prime}\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)$$\n",
    "$$m_{2}=\\mu_{2}^{\\prime}\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)$$\n",
    "$$\\vdots$$\n",
    "$$m_{k}=\\mu_{k}^{\\prime}\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**习题**\n",
    "\n",
    "设$X_{1}, \\cdots, X_{n}$是iid的$N\\left(\\theta, \\sigma^{2}\\right)$样本，求$\\theta$和$\\sigma^{2}$的矩法估计量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 极大似然法\n",
    "\n",
    "到目前为止，极大似然估计法是最为流行的求估计量的方法。\n",
    "\n",
    "**一个伯努利的例子**\n",
    "\n",
    "- 假设下列数字来自于伯努利分布的总体: 0 0 0 1 1 1 0 1 1 1\n",
    "    \n",
    "- 我们记为 $y_{1}, y_{2}, \\dots, y_{10}$\n",
    "\n",
    "- 伯努利随机变量的概率密度函数为$f(y ; p)=p^{y}(1-p)^{1-y}$, 其中 $y \\in\\{0,1\\}$. 取值为1的概率是$p$，取值为0的概率是$(1 − p)$\n",
    "\n",
    "- 我们想要推断出产生上述数字的$\\hat{p}$\n",
    "\n",
    "- 第一个数字的概率为$p^{y_{1}}(1-p)^{1-y_{1}}$，第二个数字的概率为$p^{y_{2}}(1-p)^{1-y_{2}}$，以此类推\n",
    "\n",
    "- 如果我们假设上述数字是独立得到的，那么所有10个数字的联合概率密度函数就是单个数字概率密度函数的乘积\n",
    "\n",
    "- 我们使用乘积符号$\\prod$, 例如, $\\prod_{i=1}^{2} x_{i}=x_{1} * x_{2}$\n",
    "\n",
    "- 因此我们可以写出这10个数字的联合概率密度函数或似然函数：\n",
    "\n",
    "$$L(p)=\\prod_{i=1}^{10} p^{y_{i}}(1-p)^{1-y_{i}}$$\n",
    "\n",
    "- 我们想要得到生成上述数字的$\\hat{p}$。换而言之，我们想要得到最大化似然函数 $L(p)$的$\\hat{p}$\n",
    "\n",
    "- 或者说我想要得到$\\hat{p}$，它最有可能生成上述10个数字\n",
    "\n",
    "- 其实就是通过$L(p)$对$p$求导，然后令其等于零，从而得到最优的$\\hat{p}$\n",
    "\n",
    "- 简单起见，我们一般采用似然函数的对数形式来简化求导，对数函数是单调变化，它不会改变最优的$\\hat{p}$的值\n",
    "\n",
    "- 对数变换具有如下性质：\n",
    "\n",
    "$$\\log \\left(x^{a} y^{b}\\right)=\\log \\left(x^{a}\\right)+\\log \\left(y^{b}\\right)=a * \\log (x)+b * \\log (y)$$\n",
    "\n",
    "- 对于方程取对数的优点在于把乘法形式变成了加法形式. 因此我们得到\n",
    "\n",
    "$$\\ln L(p)=\\sum_{i=1}^{n} y_{i} \\ln (p)+\\sum_{i=1}^{n}\\left(1-y_{i}\\right) \\ln (1-p)$$\n",
    "\n",
    "$$\\ln L(p)=n \\overline{y} \\ln (p)+(n-n \\overline{y}) \\ln (1-p)$$\n",
    "\n",
    "- 因此，我们就可以通过对数似然函数求偏导为零进行求解\n",
    "\n",
    "$$\\frac{d \\ln (p)}{d p}=\\frac{n \\overline{y}}{p}-\\frac{(n-n \\overline{y})}{(1-p)}=0$$\n",
    "\n",
    "- 我们可以得到$\\hat{p}\\left(y_{i}\\right)=\\overline{y}=\\sum_{i=1}^{n} \\frac{y_{i}}{n}$\n",
    "\n",
    "- 这就是MLE估计量，我们对于$p$最好的猜测就是数字序列中1的比例，在这个案例中即$p = 0.6$\n",
    "\n",
    "<br>\n",
    "\n",
    "设$X_{1}, \\cdots, X_{n}$来自以$f\\left(x | \\theta_{1}, \\cdots, \\theta_{k}\\right)$为其概率密度函数的总体的iid样本。似然函数的定义为\n",
    "\n",
    "$$L(\\theta | \\boldsymbol{x})=L\\left(\\theta_{1}, \\cdots, \\theta_{k} | x_{1}, \\cdots, x_{n}\\right)=\\prod_{i=1}^{n} f\\left(x_{i} | \\theta_{1}, \\cdots, \\theta_{k}\\right)$$\n",
    "\n",
    "**极大似然估计量**\n",
    "\n",
    "对每一个固定的样本点$x$，令$\\hat{\\theta}(\\boldsymbol{x})$是参数$\\theta$的一个取值，它使得$L(\\theta | \\boldsymbol{x})$作为$\\theta$的函数在该处达到最大值。那么，基于样本$\\mathbf{X}$的极大似然估计量（MLE）就是$\\hat{\\theta}(\\mathbf{X})$。\n",
    "\n",
    "直观上，把MLE作为一个估计量是一个合理的选择，因为在MLE这个参数点上观测样本更容易取到。\n",
    "\n",
    "<br>\n",
    "\n",
    "**习题**\n",
    "\n",
    "假设下列数字来自于正态分布的总体：\n",
    "\n",
    "90.46561，105.1319，117.5445，102.7179，102.7788，107.6234，94.87266，95.48918，75.63886，87.40594\n",
    "\n",
    "假设这些数字是独立的，求$\\mu$和$\\sigma^{2}$的MLE？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小二乘法\n",
    "\n",
    "最小二乘估计量主要用于回归模型的参数估计。它的基本思想是最小化残差平方和，从而计算得到OLS估计量。\n",
    "\n",
    "<br>\n",
    "\n",
    "**习题**\n",
    "\n",
    "求解简单线性回归模型$\\mathrm{E}\\left(Y_{i} | x_{i}\\right)=\\alpha+\\beta x_{i}$的OLS估计量\n",
    "\n",
    "<br>\n",
    "\n",
    "**习题**\n",
    "\n",
    "证明：OLS估计量是一个矩估计量\n",
    "\n",
    "<br>\n",
    "\n",
    "**习题**\n",
    "\n",
    "求解简单线性回归模型$\\mathrm{E}\\left(Y_{i} | x_{i}\\right)=\\alpha+\\beta x_{i}$的MLE估计量"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
